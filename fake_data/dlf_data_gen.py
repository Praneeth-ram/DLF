import os
import random
from datetime import date
from dotenv import load_dotenv
from faker import Faker
import psycopg2
from psycopg2 import pool
from psycopg2.extras import execute_values
import bcrypt
from tqdm import tqdm
import warnings
from urllib3.exceptions import InsecureRequestWarning

# --- NEW: Imports for PDF Generation ---
import io
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter

# Suppress the InsecureRequestWarning (if needed for your network)
warnings.filterwarnings('ignore', category=InsecureRequestWarning)

# --- Load Environment Variables ---
load_dotenv()

# --- CONFIGURATION ---
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")

# Set these to the full numbers for your final run
NUM_USERS = 50000
NUM_PROPERTIES = 10000
DOCS_PER_PROPERTY = 1
# (Other numbers for enquiries etc. can be added here)

fake = Faker('en_IN')

def get_db_connection_pool():
    print("Creating database connection pool...")
    try:
        return psycopg2.pool.SimpleConnectionPool(
            minconn=1, maxconn=10, dbname=DB_NAME, user=DB_USER,
            password=DB_PASSWORD, host=DB_HOST
        )
    except psycopg2.OperationalError as e:
        print(f"🔴 Could not connect to the database: {e}")
        return None

def setup_database_schema(cursor):
    print("Setting up database schema...")
    cursor.execute("""
        DROP TABLE IF EXISTS "OwnershipHistory", "Enquiries", "Documents", "Properties", "Users" CASCADE;
        DROP TYPE IF EXISTS "Role", "ListingStatus";
        CREATE TYPE "Role" AS ENUM ('user', 'admin');
        CREATE TYPE "ListingStatus" AS ENUM ('available', 'sold');
        CREATE TABLE "Users" (
            "user_id" INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, "name" VARCHAR(255) NOT NULL,
            "email" VARCHAR(255) UNIQUE NOT NULL, "password" VARCHAR(255) NOT NULL,
            "role" "Role" NOT NULL DEFAULT 'user', "created_at" TIMESTAMP WITH TIME ZONE DEFAULT (now())
        );
        CREATE TABLE "Properties" (
            "property_id" INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, "current_owner_id" INT REFERENCES "Users"("user_id") ON DELETE SET NULL,
            "address" VARCHAR(255) NOT NULL, "city" VARCHAR(100) NOT NULL, "state" VARCHAR(100) NOT NULL,
            "description" TEXT, "listing_status" "ListingStatus" NOT NULL DEFAULT 'available'
        );
        CREATE TABLE "Documents" (
            "document_id" INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            "property_id" INT NOT NULL REFERENCES "Properties"("property_id") ON DELETE CASCADE,
            "document_name" VARCHAR(255) NOT NULL,
            "file_content" BYTEA NOT NULL,
            "uploaded_at" TIMESTAMP WITH TIME ZONE DEFAULT (now())
        );
        CREATE TABLE "Enquiries" (
            "enquiry_id" INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, "property_id" INT NOT NULL REFERENCES "Properties"("property_id") ON DELETE CASCADE,
            "sender_id" INT NOT NULL REFERENCES "Users"("user_id") ON DELETE CASCADE, "receiver_id" INT NOT NULL REFERENCES "Users"("user_id") ON DELETE CASCADE,
            "query" TEXT NOT NULL, "sent_at" TIMESTAMP WITH TIME ZONE DEFAULT (now())
        );
        CREATE TABLE "OwnershipHistory" (
            "transfer_id" INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, "property_id" INT NOT NULL REFERENCES "Properties"("property_id") ON DELETE CASCADE,
            "previous_owner_id" INT REFERENCES "Users"("user_id") ON DELETE SET NULL, "new_owner_id" INT NOT NULL REFERENCES "Users"("user_id") ON DELETE RESTRICT,
            "admin_id" INT NOT NULL REFERENCES "Users"("user_id") ON DELETE RESTRICT, "transfer_date" TIMESTAMP WITH TIME ZONE DEFAULT (now())
        );
    """)
    print("✅ Schema created successfully.")

def generate_pdf_in_memory(content_lines):
    buffer = io.BytesIO()
    p = canvas.Canvas(buffer, pagesize=letter)
    y_position = 750 
    for line in content_lines:
        p.drawString(100, y_position, line)
        y_position -= 20
    p.showPage()
    p.save()
    buffer.seek(0)
    return buffer.getvalue()

def generate_data(conn):
    with conn.cursor() as cursor:
        setup_database_schema(cursor)

        print(f"🧍 Generating {NUM_USERS} fake users...")
        users_to_insert = []
        COMMON_PASSWORD = "Password123"
        hashed_common_password = bcrypt.hashpw(COMMON_PASSWORD.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
        for _ in tqdm(range(NUM_USERS)):
            users_to_insert.append((fake.name(), fake.unique.email(), hashed_common_password, 'user'))
        
        user_ids_tuples = execute_values(cursor, 'INSERT INTO "Users" (name, email, password, role) VALUES %s RETURNING user_id;', users_to_insert, fetch=True)
        user_ids = [item[0] for item in user_ids_tuples]
        user_id_to_name_map = {user_ids[i]: users_to_insert[i][0] for i in range(len(user_ids))}
        
        print(f"\n🏠 Generating {NUM_PROPERTIES} fake properties...")
        properties_to_insert = []
        for _ in tqdm(range(NUM_PROPERTIES)):
            properties_to_insert.append((random.choice(user_ids), fake.address().replace('\n', ', '), fake.city(), fake.state(), fake.paragraph(nb_sentences=3), random.choice(['available', 'sold'])))
        
        prop_ids_tuples = execute_values(cursor, 'INSERT INTO "Properties" (current_owner_id, address, city, state, description, listing_status) VALUES %s RETURNING property_id;', properties_to_insert, fetch=True)
        property_ids = [item[0] for item in prop_ids_tuples]
        property_id_to_owner_id_map = {property_ids[i]: properties_to_insert[i][0] for i in range(len(property_ids))}

        # ---------- ### MODIFICATION: Batch Processing for PDFs ### ----------
        print(f"\n📄 Generating PDFs and inserting into the database in batches...")
        documents_to_insert = []
        BATCH_SIZE = 1000  # Insert 1000 documents at a time
        doc_query = 'INSERT INTO "Documents" (property_id, document_name, file_content) VALUES %s;'

        # Use a new tqdm progress bar for total documents
        total_docs = len(property_ids) * DOCS_PER_PROPERTY
        with tqdm(total=total_docs) as pbar:
            for prop_id in property_ids:
                for i in range(DOCS_PER_PROPERTY):
                    doc_name = f"{random.choice(['Sale Deed', 'Tax Receipt', 'Building Plan'])} - PropID_{prop_id}_{i+1}.pdf"
                    owner_id = property_id_to_owner_id_map.get(prop_id)
                    owner_name = user_id_to_name_map.get(owner_id, "N/A")
                    
                    pdf_content_lines = [
                        f"Official Document: {doc_name}", f"Property ID: {prop_id}",
                        f"Owner Name: {owner_name}", f"Issued Date: {fake.date_this_decade()}"
                    ]
                    pdf_bytes = generate_pdf_in_memory(pdf_content_lines)
                    documents_to_insert.append((prop_id, doc_name, psycopg2.Binary(pdf_bytes)))
                    
                    # --- BATCH PROCESSING LOGIC ---
                    if len(documents_to_insert) >= BATCH_SIZE:
                        execute_values(cursor, doc_query, documents_to_insert)
                        conn.commit()  # Commit the transaction for this batch
                        documents_to_insert.clear() # Clear the list for the next batch
                    
                    pbar.update(1)

        # --- Insert any remaining documents that didn't make a full batch ---
        if documents_to_insert:
            execute_values(cursor, doc_query, documents_to_insert)
            conn.commit()

    # Final commit for the whole process (users, properties, etc.)
    conn.commit()
    print("\n\n✅ All data, including PDF files, generated and inserted into the database successfully!")

if __name__ == "__main__":
    conn_pool = get_db_connection_pool()
    if conn_pool:
        connection = None
        try:
            connection = conn_pool.getconn()
            generate_data(connection)
        except Exception as e:
            print(f"🔴 An error occurred: {e}")
            if connection:
                connection.rollback()
        finally:
            if connection:
                conn_pool.putconn(connection)
            conn_pool.closeall()
            print("Database connections closed.")

